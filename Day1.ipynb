{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ori0Ylr3kAxt"
      },
      "source": [
        "# Web Information Retrieval\n",
        "## Introduction to search engines\n",
        "\n",
        "### DAY 1: Student version\n",
        "### Introduction & First Steps\n",
        "\n",
        "The goal of this first day is to go through the data and propose some ideas for the creation of your first search engine.\n",
        "\n",
        "The notebook is divided into several steps:\n",
        "- Query on the data\n",
        "- Data extraction\n",
        "- Data exploration\n",
        "- Data Visualization\n",
        "- Ideas suggestion for the search engine\n",
        "\n",
        "The data are from the stack exchange forum. They are available here : https://archive.org/details/stackexchange\n",
        "\n",
        "\n",
        "In order to gain time, you can already download 7 zip file of datascience forum (datascience.stackexchange.com.7z). If you work on Colab, we suggest you to push it on a specific directory (it may take few minutes to load).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb6hQEdZJaBT"
      },
      "source": [
        "# Query on the data\n",
        "\n",
        "Perform SQL queries to explore the data on the surface.\n",
        "\n",
        "The queries are to be done directly from this link: https://data.stackexchange.com/datascience/query/new\n",
        "\n",
        "For each query, you must test it on the site and then rewrite it in the associated cell. A capture of the results and a comment is requested in the report.\n",
        "\n",
        "You can find a cheat sheet on SQL basic syntax at: https://res.cloudinary.com/dyd911kmh/image/upload/v1675360372/Marketing/Blog/SQL_Basics_For_Data_Science.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GPF6rwhUqORi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Posts.xml': 75730, 'Tags.xml': 682, 'Comments.xml': 78176}\n"
          ]
        }
      ],
      "source": [
        "# How many lines are in the Posts, Tags, Comments tables ?\n",
        "\n",
        "import os\n",
        "\n",
        "path_to_folder = \"/home/lucien/datascience.stackexchange.com\"\n",
        "\n",
        "L = ['Posts.xml', 'Tags.xml', 'Comments.xml']\n",
        "count_lines = {}\n",
        "\n",
        "for filename in os.listdir(path_to_folder):\n",
        "    if filename in L:\n",
        "        with open(os.path.join(path_to_folder, filename)) as f:\n",
        "            count_lines[filename] = len(f.readlines())\n",
        "print(count_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "epn2j17pqPIC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le nombre de commentaires est de : 1082\n"
          ]
        }
      ],
      "source": [
        "# How many comments have there been since the beginning of the year 2023? \n",
        "#on veit compter le nombre de balises row Ã  l'interieur des balises comments de Comments.xml\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "path_to_comments = \"/home/lucien/datascience.stackexchange.com/Comments.xml\"\n",
        "\n",
        "count_comments = 0\n",
        "\n",
        "for event, elem in ET.iterparse(path_to_comments):\n",
        "    if elem.tag == \"row\":\n",
        "        if int(elem.attrib[\"CreationDate\"][0:4]) >= 2023:\n",
        "            count_comments += 1\n",
        "\n",
        "print('Le nombre de commentaires est de :', count_comments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SkOl7AHlqT1H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le nombre d'utilisateurs est de : 125306\n"
          ]
        }
      ],
      "source": [
        "# How many users are there ?\n",
        "\n",
        "path_to_users = \"/home/lucien/datascience.stackexchange.com/Users.xml\"\n",
        "\n",
        "count_users = 0\n",
        "\n",
        "for event, elem in ET.iterparse(path_to_users):\n",
        "    if elem.tag == \"row\":\n",
        "        count_users += 1\n",
        "\n",
        "print('Le nombre d\\'utilisateurs est de :', count_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTiguRqKqV5c"
      },
      "outputs": [],
      "source": [
        "# How many new users are there each year since 2020 ?\n",
        "path_to_users = \"/home/lucien/datascience.stackexchange.com/Users.xml\"\n",
        "\n",
        "count_users = 0\n",
        "\n",
        "for event, elem in ET.iterparse(path_to_users):\n",
        "    if elem.tag == \"row\":\n",
        "        if int(elem.attrib[\"CreationDate\"][0:4]) >= 2020:\n",
        "            count_users += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kltcQv74qYBw"
      },
      "outputs": [],
      "source": [
        "# What is the Content of the smallest Post ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mJQ9f2-qbMA"
      },
      "outputs": [],
      "source": [
        "# What is the most voted post ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FzkIPeAqeVB"
      },
      "outputs": [],
      "source": [
        "# What are the 10 most frequent tags in 2022? (ordered from most to least frequent)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eePn_HW4qlUm"
      },
      "source": [
        "## Initialize the environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqwXLcP_qmrz"
      },
      "outputs": [],
      "source": [
        "## Install the library for extracting 7 zip file\n",
        "!pip install py7zr --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yacdJePmqo8g"
      },
      "outputs": [],
      "source": [
        "## Import the libraries\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import py7zr\n",
        "import os"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8FmfwnjOqv3G"
      },
      "source": [
        "There is a simple method for extracting the data directly from the website zip repo. It writes the different files directly in your google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Laiz3w_YqrNu"
      },
      "outputs": [],
      "source": [
        "# Only if you use Colab\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM12A6cYqy3-"
      },
      "outputs": [],
      "source": [
        "# To adapt to your Drive/local directory\n",
        "\n",
        "MAIN_PATH = '/content/drive/MyDrive/TP Centrale'\n",
        "DATA_PATH = '/content/drive/MyDrive/TP Centrale/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq-JymDaq1O6"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(MAIN_PATH):\n",
        "  os.mkdir(MAIN_PATH)\n",
        "if not os.path.isdir(MAIN_PATH):\n",
        "  os.mkdir(DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OIJnSUPq6Wo"
      },
      "outputs": [],
      "source": [
        "archive = py7zr.SevenZipFile(os.path.join(MAIN_PATH, 'datascience.stackexchange.com.7z'), mode='r')\n",
        "archive.extractall(path=os.path.join(MAIN_PATH, 'data'))\n",
        "archive.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7wnLEyhJrC1o"
      },
      "source": [
        "## Data Extraction\n",
        "\n",
        "The data is in XML format. Why do you think the developers preferred this format? What could have been other possible formats? (**answer expected in the report**)\n",
        "\n",
        "Here is what a raw file looks like:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf-Y3oQXxYxq"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(DATA_PATH, 'Tags.xml'), 'r') as f:\n",
        "  raw_xml = f.read()\n",
        "print(raw_xml)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oZJBY1b8xUPI"
      },
      "source": [
        "### XML Extraction example for Tags file\n",
        "Here is a method to read these XML files easily as a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhGdQYNqrD7G"
      },
      "outputs": [],
      "source": [
        "tags = pd.read_xml(os.path.join(DATA_PATH, 'Tags.xml'), parser=\"etree\", encoding=\"utf8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I67TIuTirGL5"
      },
      "outputs": [],
      "source": [
        "tags"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LwP3rCDsyCHp"
      },
      "source": [
        "There are several other files in the extracted folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2o52jt7yJ51"
      },
      "outputs": [],
      "source": [
        "os.listdir(DATA_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C1wORbZGyMMo"
      },
      "source": [
        "In the next part you will do some exploration on them, starting with the more important one: Posts.xml. It contains the many posts of the selected topic: \"data science\"."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TrRSDOzPrLet"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "In this part, you have to work on Posts.xml file.\n",
        "\n",
        "\n",
        "You can find a cheat sheet of pandas basic syntax at: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpZTYciRrIIs"
      },
      "outputs": [],
      "source": [
        "# Open the Posts.xml file\n",
        "\n",
        "posts = pd.read_xml(os.path.join(DATA_PATH, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")\n",
        "posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeGfUGDnrSpE"
      },
      "outputs": [],
      "source": [
        "# What is the size of this file ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvPpey1brruH"
      },
      "outputs": [],
      "source": [
        "# What is the schema of the posts table ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpItDd1Truqv"
      },
      "outputs": [],
      "source": [
        "# Give the mean number of new posts by user "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ2rUO4DrxMU"
      },
      "outputs": [],
      "source": [
        "# Run some other queries to get a better understanding of the \"Posts\" table"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3J1FfGVNr1ja"
      },
      "source": [
        "## Data Visualization \n",
        "\n",
        "Exploring data only through queries has its limits. \n",
        "\n",
        "An important step in understanding the data is in the visualization. It is important to think about what information I want to put forward and how.\n",
        "\n",
        "You have the matplotlib and seaborn libraries available:\n",
        "- https://matplotlib.org/stable/index.html\n",
        "- https://seaborn.pydata.org/\n",
        "\n",
        "\n",
        "You can find some cheatsheets at:\n",
        " - for matplotlib: https://matplotlib.org/cheatsheets/\n",
        " - for seaborn: https://res.cloudinary.com/dyd911kmh/image/upload/v1676302629/Marketing/Blog/Seaborn_Cheat_Sheet.pdf\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "reWXnXkdr_-n"
      },
      "source": [
        "#### Example of matplotlib use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a3Urfzsr49v"
      },
      "outputs": [],
      "source": [
        "tags_5 = tags.head(5)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5), layout='constrained')\n",
        "\n",
        "plt.bar(x=tags_5[\"TagName\"], height=tags_5[\"Count\"], width=0.4)\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Posts count')\n",
        "ax.set_title('Distribution of Posts count by Tag')\n",
        "ax.set_ylim(0, 12_000)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rFBMPI8qsF9Q"
      },
      "source": [
        "#### Example of seaborn use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyx3MZ_asDOz"
      },
      "outputs": [],
      "source": [
        "tags_5 = tags.head(5)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5), layout='constrained')\n",
        "\n",
        "sns.barplot(x=tags_5[\"TagName\"], y=tags_5[\"Count\"], width=0.4)\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Posts count')\n",
        "ax.set_title('Distribution of Posts count by Tag')\n",
        "ax.set_ylim(0, 12_000)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1vHw-rh9sdFL"
      },
      "source": [
        "These were 2 examples of distribution visualization via histograms.\n",
        "\n",
        "On Seaborn, several types of fairly intuitive graphs are available. They are classified by type of input data:\n",
        "- Visualize 2 continuous variables: relplot\n",
        "- Visualize 1 continuous variable in relation to a categorical variable: displot\n",
        "- Visualize 2 categorical variables : catplot\n",
        "\n",
        "![image.png](https://seaborn.pydata.org/_images/function_overview_8_0.png)\n",
        "\n",
        "\n",
        "More examples can be found here : https://seaborn.pydata.org/tutorial/function_overview.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZEe7iqxsihH"
      },
      "outputs": [],
      "source": [
        "# Viz 1 : Plot the distribution of number of posts created by users\n",
        "\n",
        "# Directly use histplot takes too long because of the number of users.\n",
        "# Better to aggregate and then use barplot\n",
        "\n",
        "# Doesn't take into account users that have never created posts\n",
        "\n",
        "posts_count = posts.groupby(\"OwnerUserId\", as_index=False)[\"Id\"].count()\n",
        "posts_count = posts_count.rename(columns={\"Id\": \"postNumber\"})\n",
        "posts_count_number = posts_count.groupby(\"postNumber\", as_index=False).count()\n",
        "\n",
        "sns.barplot(x=\"postNumber\", y=\"OwnerUserId\", data=posts_count_number)\n",
        "plt.xlim((0, 10))\n",
        "plt.ylabel(\"Number of New Posts\")\n",
        "plt.title(\"Distribution of the number of users by new posts number\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omajwmj1s3Ql"
      },
      "outputs": [],
      "source": [
        "# Viz 2 : Plot the distribution of number of posts by months\n",
        "posts[\"month_creation_date\"] = pd.to_datetime(posts.CreationDate).dt.month\n",
        "\n",
        "posts_by_month = posts.groupby(\"month_creation_date\", as_index=False)[\"OwnerUserId\"].count()\n",
        "\n",
        "sns.barplot(x=\"month_creation_date\", y=\"OwnerUserId\", data=posts_by_month)\n",
        "plt.ylabel(\"Number of New Posts\")\n",
        "plt.title(\"Distribution of the new posts number by months\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx2iVYoTtLBJ"
      },
      "outputs": [],
      "source": [
        "# Viz 3 : Plot the distribution of number of characters by posts and by year starting from 2020\n",
        "posts[\"CreationDateYear\"] = pd.to_datetime(posts.CreationDate).dt.year\n",
        "\n",
        "posts_sup2020 = posts[posts.CreationDateYear > 2020]\n",
        "\n",
        "posts_sup2020[\"nbCaracters\"] = posts_sup2020.Body.str.len()\n",
        "\n",
        "sns.histplot(x=\"nbCaracters\", hue=\"CreationDateYear\", data=posts_sup2020)\n",
        "plt.xlim((0, 5000))\n",
        "plt.ylabel(\"Number of Characters\")\n",
        "plt.title(\"Distribution of the number of characters by posts and by users\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz2HP6O9tT-3"
      },
      "outputs": [],
      "source": [
        "# Add other visualization figures that can help you to decide the search engine architecture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mhDTfggBtWYM"
      },
      "source": [
        "## Exploring Other Files\n",
        "\n",
        "The purpose of this part is to understand the other files using the same process and data collection site: https://archive.org/details/stackexchange\n",
        "\n",
        "You will describe the purpose and content of each file to show your understanding of the subject. You will also make a relational diagram of the different tables directly in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4gGnRTKtcBp"
      },
      "outputs": [],
      "source": [
        "# Open, explore and visualize other XML files to suggest features for your search engines"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gU11G80rtfld"
      },
      "source": [
        "## Suggest ideas for the search engine\n",
        "\n",
        "Using your work and knowledge of this database, propose a structure for your search engine in the report. You do not need to code it entirely yet, simply write down some ideas you may already have on how you could build a great search engine, which data to use and how to use it.\n",
        "\n",
        "Reminder: The aim is to provide a search engine able to find information from any of the files with textual data in it (posts, comments, ...) on the datascience topic. Some files might be better than others when it comes to searching for information, some metadata could be used aswell... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpW9E16gzVIu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
